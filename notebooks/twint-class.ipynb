{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InÂ \\[81\\]:\n",
    "\n",
    "    import twint \n",
    "    import nest_asyncio\n",
    "    import asyncio\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pylab as plt\n",
    "    import re\n",
    "    from textblob import TextBlob\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "    import torch\n",
    "\n",
    "Classes 1 \"Scraping Section\"\n",
    "\n",
    "<a href=\"#Classes-1-%22Scraping-Section%22\" class=\"anchor-link\">Â¶</a>\n",
    "\n",
    "InÂ \\[82\\]:\n",
    "\n",
    "    #Class for Data Collection\n",
    "    class Tweets_Scraping:\n",
    "        #Impelementation of the constructor\n",
    "        def __init__(self,key_word=\"Tesla\",lang=\"en\",min_l=30,limit=100):\n",
    "            self.conf=twint.Config()\n",
    "            self.s=key_word\n",
    "            self.lang=lang\n",
    "            self.min=min_l\n",
    "            self.lim=limit\n",
    "        \n",
    "        #For Collecting tweets and creating the DataFrame\n",
    "        def scraping_tweets(self,key=None,lang=None,min_l=None,limit=None):\n",
    "            if key is None:\n",
    "                key=self.s\n",
    "                \n",
    "            if lang is None:\n",
    "                lang=self.lang\n",
    "                \n",
    "            if min_l is None:\n",
    "                min_l=self.min\n",
    "                \n",
    "            if limit is None:\n",
    "                limit=self.lim\n",
    "            nest_asyncio.apply() \n",
    "            self.conf.Limit=limit\n",
    "            self.conf.Lang = lang\n",
    "            self.conf.Search =key\n",
    "            self.conf.Hide_output=True\n",
    "            self.conf.Min_likes =min_l\n",
    "            self.conf.Pandas=True\n",
    "            twint.run.Search(self.conf)\n",
    "            df = twint.storage.panda.Tweets_df\n",
    "            return df\n",
    "\n",
    "Classes 2 \"Pre-Processing Section\"\n",
    "\n",
    "<a href=\"#Classes-2-%22Pre-Processing-Section%22\"\n",
    "class=\"anchor-link\">Â¶</a>\n",
    "\n",
    "InÂ \\[83\\]:\n",
    "\n",
    "    #Class for Dealing with Data, preparing it and analysing it\n",
    "        \n",
    "    class Data_preprocessing:\n",
    "        #Function use for dealing with missing data\n",
    "        def handle_missing_data(self,df,column,fill_with):\n",
    "            df[column]=df[column].replace(np.nan,fill_with)\n",
    "            \n",
    "        # Function used to remove and clean tweets from special chracters\n",
    "        def clean_tweets_content(self, tweet):\n",
    "            return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(RT)\", \" \", tweet).split())\n",
    "        \n",
    "        #This function is used to get the percentage of dataset column\n",
    "        def get_col_percentage(self,col,df):\n",
    "            \n",
    "            total=df[col].value_counts()\n",
    "            percentage=round(df[col].value_counts(dropna=False,normalize=True)*100,3)\n",
    "            # or percentage=round((df[col]/df[col].sum())*100,2)\n",
    "            res=pd.concat([total,percentage],axis=1,keys=[\"Total No.\",\"Percentage\"])\n",
    "            #res['Percentage'] = res['Percentage'].astype(str) + '%'\n",
    "            return res\n",
    "\n",
    "Classes 3 \"Sentiment Analysis Section\"\n",
    "\n",
    "<a href=\"#Classes-3-%22Sentiment-Analysis-Section%22\"\n",
    "class=\"anchor-link\">Â¶</a>\n",
    "\n",
    "InÂ \\[85\\]:\n",
    "\n",
    "    class Sentiment_Analysis:\n",
    "        \n",
    "        def __init__(self,analyze_method):\n",
    "            self.analyze_method=analyze_method\n",
    "            \n",
    "        #Function used for applying sentiment analysis based on the input method \"Object\"\n",
    "        def sentiment_analysis_method(self,tweet_content):\n",
    "            pre=Data_preprocessing()\n",
    "            try:\n",
    "                if self.analyze_method.lower() == \"textblob\":\n",
    "                    analysis = TextBlob(pre.clean_tweets_content(tweet_content))\n",
    "                    if analysis.sentiment.polarity > 0:\n",
    "                        return 1\n",
    "                    elif analysis.sentiment.polarity == 0:\n",
    "                        return 0\n",
    "                    else:\n",
    "                        return -1\n",
    "                    \n",
    "                elif self.analyze_method.lower() ==\"bert\":\n",
    "                    tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "                    model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "                    tokens = tokenizer.encode(pre.clean_tweets_content(tweet_content), return_tensors='pt')\n",
    "                    result = model(tokens)\n",
    "                    return int(torch.argmax(result.logits))+1\n",
    "                \n",
    "                else:\n",
    "                    return 7\n",
    "            \n",
    "            except Exception:\n",
    "                print(\"Error!!!, Check Your Inputs Again, Please\")\n",
    "\n",
    "InÂ \\[21\\]:\n",
    "\n",
    "    #t=Tweets_Scraping()\n",
    "\n",
    "InÂ \\[22\\]:\n",
    "\n",
    "    #df=t.scraping_tweets(key=\"Tesla\",limit=1000,lang=\"en\")\n",
    "\n",
    "InÂ \\[23\\]:\n",
    "\n",
    "    #df.language.value_counts()\n",
    "\n",
    "InÂ \\[24\\]:\n",
    "\n",
    "    #df.head()\n",
    "\n",
    "InÂ \\[12\\]:\n",
    "\n",
    "    #df.to_csv(\"h.csv\")\n",
    "\n",
    "InÂ \\[68\\]:\n",
    "\n",
    "    df=pd.read_csv(\"h.csv\")\n",
    "\n",
    "InÂ \\[69\\]:\n",
    "\n",
    "    #Exploring Data\n",
    "    df.head()\n",
    "\n",
    "Out\\[69\\]:\n",
    "\n",
    "|     | Unnamed: 0 | id                  | conversation_id     | created_at   | date                | timezone | place | tweet                                             | language | hashtags                  | ... | geo | source | user_rt_id | user_rt | retweet_id | reply_to | retweet_date | translate | trans_src | trans_dest |\n",
    "|-----|------------|---------------------|---------------------|--------------|---------------------|----------|-------|---------------------------------------------------|----------|---------------------------|-----|-----|--------|------------|---------|------------|----------|--------------|-----------|-----------|------------|\n",
    "| 0   | 0          | 1510261577806721031 | 1510261577806721031 | 1.648909e+12 | 2022-04-02 16:23:14 | 200      | NaN   | The day I learned Tesla's had this feature ðŸ™„     | en       | \\[\\]                      | ... | NaN | NaN    | NaN        | NaN     | NaN        | \\[\\]     | NaN          | NaN       | NaN       | NaN        |\n",
    "| 1   | 1          | 1510259733223161858 | 1510259733223161858 | 1.648909e+12 | 2022-04-02 16:15:54 | 200      | NaN   | Okâ€¦.Newport to Austin - here we go!! #CyberRod... | en       | \\['cyberrodeo', 'tesla'\\] | ... | NaN | NaN    | NaN        | NaN     | NaN        | \\[\\]     | NaN          | NaN       | NaN       | NaN        |\n",
    "| 2   | 2          | 1510258033879924739 | 1510258033879924739 | 1.648909e+12 | 2022-04-02 16:09:09 | 200      | NaN   | Epic Final 4, Tesla 1Q deliveries, then Master... | en       | \\['tarheels'\\]            | ... | NaN | NaN    | NaN        | NaN     | NaN        | \\[\\]     | NaN          | NaN       | NaN       | NaN        |\n",
    "| 3   | 3          | 1510251249408434179 | 1510251249408434179 | 1.648907e+12 | 2022-04-02 15:42:11 | 200      | NaN   | This @Tesla fandom stuff is getting out of con... | en       | \\[\\]                      | ... | NaN | NaN    | NaN        | NaN     | NaN        | \\[\\]     | NaN          | NaN       | NaN       | NaN        |\n",
    "| 4   | 4          | 1510249279247380482 | 1510249279247380482 | 1.648906e+12 | 2022-04-02 15:34:21 | 200      | NaN   | Amazing Drone Video Shows How Tesla Model Y Is... | en       | \\[\\]                      | ... | NaN | NaN    | NaN        | NaN     | NaN        | \\[\\]     | NaN          | NaN       | NaN       | NaN        |\n",
    "\n",
    "5 rows Ã— 39 columns\n",
    "\n",
    "InÂ \\[70\\]:\n",
    "\n",
    "    df.columns\n",
    "\n",
    "Out\\[70\\]:\n",
    "\n",
    "    Index(['Unnamed: 0', 'id', 'conversation_id', 'created_at', 'date', 'timezone',\n",
    "           'place', 'tweet', 'language', 'hashtags', 'cashtags', 'user_id',\n",
    "           'user_id_str', 'username', 'name', 'day', 'hour', 'link', 'urls',\n",
    "           'photos', 'video', 'thumbnail', 'retweet', 'nlikes', 'nreplies',\n",
    "           'nretweets', 'quote_url', 'search', 'near', 'geo', 'source',\n",
    "           'user_rt_id', 'user_rt', 'retweet_id', 'reply_to', 'retweet_date',\n",
    "           'translate', 'trans_src', 'trans_dest'],\n",
    "          dtype='object')\n",
    "\n",
    "InÂ \\[71\\]:\n",
    "\n",
    "    #Dropping unuseful features\n",
    "    df.drop(columns=[\"id\",\"place\",\"Unnamed: 0\"\n",
    "                     ,\"urls\",\"photos\",\"video\",\n",
    "                    \"thumbnail\",\"quote_url\"\n",
    "                     ,\"conversation_id\",\"created_at\",\n",
    "                     'geo', 'source', 'user_rt_id', 'user_rt',\n",
    "                    'retweet_id', 'reply_to', 'retweet_date'\n",
    "                     , 'translate', 'trans_src',\n",
    "                    'trans_dest',\"near\"\n",
    "                    ],axis=1,inplace=True, errors='ignore')\n",
    "\n",
    "InÂ \\[73\\]:\n",
    "\n",
    "    #Checking for Nulls in the remaining features \n",
    "    df.isna().sum()\n",
    "\n",
    "Out\\[73\\]:\n",
    "\n",
    "    date           0\n",
    "    timezone       0\n",
    "    tweet          0\n",
    "    language       0\n",
    "    hashtags       0\n",
    "    cashtags       0\n",
    "    user_id        0\n",
    "    user_id_str    0\n",
    "    username       0\n",
    "    name           0\n",
    "    day            0\n",
    "    hour           0\n",
    "    link           0\n",
    "    retweet        0\n",
    "    nlikes         0\n",
    "    nreplies       0\n",
    "    nretweets      0\n",
    "    search         0\n",
    "    dtype: int64\n",
    "\n",
    "InÂ \\[74\\]:\n",
    "\n",
    "    d=Data_preprocessing()\n",
    "\n",
    "InÂ \\[75\\]:\n",
    "\n",
    "    #Cleaning \"tweet\" column using regex\n",
    "    df.tweet=df.tweet.apply(lambda x:d.clean_tweets_content(x))\n",
    "\n",
    "InÂ \\[87\\]:\n",
    "\n",
    "    senti=Sentiment_Analysis(\"TextBlob\");\n",
    "\n",
    "InÂ \\[88\\]:\n",
    "\n",
    "    #sentiment Analysis process using \"TextBlob\"\n",
    "    df[\"sentiment_res\"]=df.tweet.apply(lambda x:senti.sentiment_analysis_method(x))\n",
    "\n",
    "InÂ \\[91\\]:\n",
    "\n",
    "    d.get_col_percentage(\"sentiment_res\",df)\n",
    "\n",
    "Out\\[91\\]:\n",
    "\n",
    "|     | Total No. | Percentage |\n",
    "|-----|-----------|------------|\n",
    "| 1   | 510       | 51.0       |\n",
    "| 0   | 317       | 31.7       |\n",
    "| -1  | 173       | 17.3       |\n",
    "\n",
    "Draft\n",
    "\n",
    "<a href=\"#Draft\" class=\"anchor-link\">Â¶</a>\n",
    "\n",
    "InÂ \\[25\\]:\n",
    "\n",
    "    # c = twint.Config()\n",
    "    # c.Limit=100\n",
    "    # c.Lang = \"en\"\n",
    "    # c.Search = \"pizza\"\n",
    "    # c.Hide_output=True\n",
    "    # c.Min_likes = 30\n",
    "    # c.Pandas=True\n",
    "    # twint.run.Search(c)\n",
    "    # df = twint.storage.panda.Tweets_df\n",
    "    # df.head()"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
