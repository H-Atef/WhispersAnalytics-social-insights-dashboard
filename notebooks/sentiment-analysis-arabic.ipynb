{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \\[38\\]:\n",
    "\n",
    "    from camel_tools.sentiment import SentimentAnalyzer\n",
    "    from transformers import AutoTokenizer,AutoModelForSequenceClassification,pipeline\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "In \\[39\\]:\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\")\n",
    "    model =AutoModelForSequenceClassification.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\")\n",
    "    #snt = SentimentAnalyzer(\"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\")\n",
    "    #sa = pipeline('text-classification', model='CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment')\n",
    "\n",
    "In \\[110\\]:\n",
    "\n",
    "    #Arabic Preprocessing\n",
    "    class Arabic_Preprocessing:\n",
    "        \n",
    "        def cleaning_arabic_content(self,text):  \n",
    "            if text is None:\n",
    "                text=\"\"\n",
    "                return text\n",
    "            search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",'\"',\"ـ\",\"'\",\"ى\",\n",
    "                  \"\\\\\",'\\n', '\\t','&quot;','?','؟','!']\n",
    "            replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\n",
    "                       \"\",\"\",\"\",\"ي\",\"\",' ', ' ',' ',' ? ',' ؟ ', ' ! ']\n",
    "            #remove tashkeel\n",
    "            tashkeel = re.compile(r'[\\u0617-\\u0618-\\u0619-\\u061A\\u064B-\\u0652-\\u064C-\\u064D-\\u064E-\\u064F-\\u0650-\\u0651-\\u0652-\\u0653-\\u0654-\\u0655]')\n",
    "            text = re.sub(tashkeel,\"\", text)\n",
    "\n",
    "            longation = re.compile(r'(.)\\1+')\n",
    "            subst = r\"\\1\\1\"\n",
    "            \n",
    "            text = re.sub(longation, subst, text)\n",
    "\n",
    "            text = re.sub(r\"[^\\w\\s]\", '', text)\n",
    "            \n",
    "            #remove english words\n",
    "            text = re.sub(r\"[a-zA-Z]\", '', text)\n",
    "            \n",
    "            #remove spaces\n",
    "            text = re.sub(r\"\\d+\", ' ', text)\n",
    "            text = re.sub(r\"\\n+\", ' ', text)\n",
    "            text = re.sub(r\"\\t+\", ' ', text)\n",
    "            text = re.sub(r\"\\r+\", ' ', text)\n",
    "            text = re.sub(r\"\\s+\", ' ', text)\n",
    "            \n",
    "            #remove repetetions\n",
    "            text = text.replace('وو', 'و')\n",
    "            text = text.replace('يي', 'ي')\n",
    "            text = text.replace('اا', 'ا')\n",
    "\n",
    "            for i in range(0, len(search)):\n",
    "                text = text.replace(search[i], replace[i])\n",
    "\n",
    "            text = text.strip()\n",
    "\n",
    "            return text\n",
    "\n",
    "    #Arabic Sentiment Analysis Class\n",
    "    class Arabic_Sentiment:\n",
    "        \n",
    "        def arabic_sentiment_analysis(self,content):\n",
    "            pre=Arabic_Preprocessing()\n",
    "            #Using Camel Tools\n",
    "            #res=snt.predict_sentence(content)\n",
    "            \n",
    "            #Using pipeline from transformers\n",
    "            #res=sa([content])[0][\"label\"]\n",
    "            \n",
    "            labels=[\"positive\",\"negative\",\"neutral\"]\n",
    "            tokens = tokenizer.encode(content, return_tensors='pt')\n",
    "            result = model(tokens)\n",
    "            res=labels[int(torch.argmax(result.logits,dim=-1))]\n",
    "            return res\n",
    "            \n",
    "        \n",
    "\n",
    "In \\[104\\]:\n",
    "\n",
    "    senti=Arabic_Sentiment()\n",
    "\n",
    "In \\[105\\]:\n",
    "\n",
    "    df=pd.read_csv(\"arabic.csv\")\n",
    "\n",
    "In \\[106\\]:\n",
    "\n",
    "    pre=Arabic_Preprocessing()\n",
    "    df.tweet=df.tweet.apply(pre.cleaning_arabic_content)\n",
    "\n",
    "In \\[111\\]:\n",
    "\n",
    "    for e,i in enumerate(df.tweet[:10]):\n",
    "        print(e,i)\n",
    "\n",
    "    0 طب وو وواوروبا كانو بيحرقو فلوس يااستاذ حليم\n",
    "    1 انا وسطي واليسار اللبناني التكفيري يللي بنتقد تطرفه ما خصه اصلا باليسار\n",
    "    2 اللهم تقبل منا ومنكم\n",
    "    3 انا لا فرح لا حزن بصراحه كنتمني نبكي ولكن للاسف لا استطيع\n",
    "    4 تاني سنه يتخالف فيها رؤيه الهلال مع مكه اذا العيد عندكم غير عندنا وعرفه عندكم غير عرفه عندنا والحجيج المغاربه سيقفوا علي عرفه في يوم ليس عندهم عرفه\n",
    "    5 ويوم عرفه في السعوديه الحجاج يقفون بعرفه يوم الجمعه والعيد يوم السبت المغرب يوم عرفه هو يوم السبت وعرفه مافيه حتواحد\n",
    "    6 تحليل فني لسهم تسلا يتوقع اختبار الدعم عند دولار\n",
    "    7 هاي الكيكه من عدنا الك ايلون بلكي تشتري دوج كوين بمناسبه عيد ميلادك\n",
    "    8 عطاك الله الصحه\n",
    "    9 ليس كل ما يقوله وحيا افكاره من اسباب ثوره قوس قزح الهمجيه\n",
    "\n",
    "In \\[112\\]:\n",
    "\n",
    "    df[\"Arab_Sentiment\"]=df.tweet.apply(senti.arabic_sentiment_analysis)\n",
    "\n",
    "In \\[115\\]:\n",
    "\n",
    "    df.Arab_Sentiment=df.Arab_Sentiment.map(lambda x: x.capitalize())\n",
    "    df.Arab_Sentiment.value_counts()\n",
    "\n",
    "Out\\[115\\]:\n",
    "\n",
    "    Negative    52\n",
    "    Positive    37\n",
    "    Neutral     29\n",
    "    Name: Arab_Sentiment, dtype: int64"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
